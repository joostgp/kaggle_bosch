{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Custom modules\n",
    "import const\n",
    "import func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning <open file '/Volumes/My Book/kaggle_bosch/train_numeric.pkl', mode 'rb' at 0x115b36a50>.pkl\n"
     ]
    }
   ],
   "source": [
    "# Numeric data\n",
    "num_dat = func.load_data_file('train_numeric')\n",
    "\n",
    "y = num_dat['data']['y']\n",
    "data = num_dat['data']['features']\n",
    "ids = num_dat['data']['ids']\n",
    "n_f_names = num_dat['data']['feature_names'][1:]\n",
    "\n",
    "del num_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning <open file '/Volumes/My Book/kaggle_bosch/test_numeric.pkl', mode 'rb' at 0x115b36a50>.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load numeric data test\n",
    "num_dat = func.load_data_file('test_numeric')\n",
    "ids_test = num_dat['data']['ids']\n",
    "data = vstack([data, num_dat['data']['features']], format='csr')\n",
    "del num_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_all = pd.concat([ids, ids_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_1 = y[y.Response==1].index.values\n",
    "n_0 = y[y.Response==0].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id\n",
       "0   1\n",
       "1   2\n",
       "2   3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = y.reindex(pd.concat([ids.Id, ids_test.Id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>station</th>\n",
       "      <th>feature_nr</th>\n",
       "      <th>feat_nr_dat</th>\n",
       "      <th>name_dat</th>\n",
       "      <th>name_cat</th>\n",
       "      <th>name_num</th>\n",
       "      <th>col_dat</th>\n",
       "      <th>col_num</th>\n",
       "      <th>col_cat</th>\n",
       "      <th>station_V2</th>\n",
       "      <th>line_V2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L0_S0_D1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L0_S0_F0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>L0_S0_D3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L0_S0_F2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>L0_S0_D5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L0_S0_F4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line  station  feature_nr  feat_nr_dat  name_dat name_cat  name_num  \\\n",
       "0     0        0           0          1.0  L0_S0_D1      NaN  L0_S0_F0   \n",
       "1     0        0           2          3.0  L0_S0_D3      NaN  L0_S0_F2   \n",
       "2     0        0           4          5.0  L0_S0_D5      NaN  L0_S0_F4   \n",
       "\n",
       "   col_dat  col_num  col_cat  station_V2  line_V2  \n",
       "0      0.0      0.0      NaN         0.0      1.0  \n",
       "1      1.0      1.0      NaN         0.0      1.0  \n",
       "2      2.0      2.0      NaN         0.0      1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load look-up table\n",
    "lut = pd.read_csv(const.LOOK_UP_TABLE)\n",
    "lut.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>t_0.0</th>\n",
       "      <th>t_1.0</th>\n",
       "      <th>t_2.0</th>\n",
       "      <th>t_3.0</th>\n",
       "      <th>t_4.0</th>\n",
       "      <th>t_5.0</th>\n",
       "      <th>t_6.0</th>\n",
       "      <th>t_7.0</th>\n",
       "      <th>t_8.0</th>\n",
       "      <th>...</th>\n",
       "      <th>t_42.0</th>\n",
       "      <th>t_43.0</th>\n",
       "      <th>t_44.0</th>\n",
       "      <th>t_45.0</th>\n",
       "      <th>t_46.0</th>\n",
       "      <th>t_47.0</th>\n",
       "      <th>t_48.0</th>\n",
       "      <th>t_49.0</th>\n",
       "      <th>t_50.0</th>\n",
       "      <th>t_51.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>8224.0</td>\n",
       "      <td>8224.0</td>\n",
       "      <td>8224.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8226.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8226.0</td>\n",
       "      <td>8227.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>161870.0</td>\n",
       "      <td>161870.0</td>\n",
       "      <td>161870.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161872.0</td>\n",
       "      <td>161872.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161873.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id     t_0.0     t_1.0     t_2.0  t_3.0   t_4.0     t_5.0     t_6.0  \\\n",
       "0   4    8224.0    8224.0    8224.0    NaN  8226.0       NaN       NaN   \n",
       "1   6       NaN       NaN       NaN    NaN     NaN       NaN       NaN   \n",
       "2   7  161870.0  161870.0  161870.0    NaN     NaN  161872.0  161872.0   \n",
       "\n",
       "    t_7.0     t_8.0   ...    t_42.0  t_43.0  t_44.0  t_45.0  t_46.0  t_47.0  \\\n",
       "0  8226.0    8227.0   ...       NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1     NaN       NaN   ...       NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2     NaN  161873.0   ...       NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   t_48.0  t_49.0  t_50.0  t_51.0  \n",
       "0     NaN     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[3 rows x 129 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read start time per station (discard features related to t delta)\n",
    "t_station = pd.read_csv(os.path.join(const.DATA_PATH, 'feat_set_date_station.csv')).iloc[:,:129]\n",
    "t_station.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2367495"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_detrended_numeric_feature(ft_nr, showplot=True, cluster = 'cluster_n8'):\n",
    "    # For a given numeric features\n",
    "    # Get station of feature\n",
    "    # Get station time per sample\n",
    "    # Get samples with value at this feature\n",
    "    # Combine both to dataframe\n",
    "    # Group dataframe by sec and take mean\n",
    "    # Subtract this mean from each value\n",
    "    #n = 0.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get station number \n",
    "    station = lut[lut.feature_nr==ft_nr].station_V2.values[0]\n",
    "    \n",
    "    # Column nr in sparse array\n",
    "    n_col = lut[lut.feature_nr==ft_nr].col_num.values[0]\n",
    "    \n",
    "    if not n_col>=0:\n",
    "        return None\n",
    "    \n",
    "    # Samples with value for this feature\n",
    "    i_n = data[:, n_col].nonzero()[0]\n",
    "    \n",
    "    # Timestamps for these values from station\n",
    "    i_t = (~t_station.iloc[i_n, t_station.columns.get_loc('t_' + str(station))].isnull()).index.values\n",
    "\n",
    "    # Samples with value and timestamp\n",
    "    i = list(set(i_n) & set(i_t))\n",
    "    \n",
    "    # Get value, timestamp, Response and cluster for each sample and combine in DataFrame\n",
    "    v = data[i, n_col].todense().A1\n",
    "    t = 1.0/100*t_station.iloc[i, t_station.columns.get_loc('t_' + str(station))].values\n",
    "    r = y.iloc[i]['Response'].values\n",
    "    c = cluster_info.iloc[i][cluster].values\n",
    "    c50 = cluster_info.iloc[i]['cluster_n50'].values\n",
    "    c150 = cluster_info.iloc[i]['cluster_n150'].values\n",
    "    c500 = cluster_info.iloc[i]['cluster_n500'].values\n",
    "    \n",
    "    df = pd.DataFrame({'i':i, 't':t,'v':v, 'r':r, 'c':c, 'c50':c50, 'c150':c150, 'c500':c500})\n",
    "\n",
    "    # Check nan in t (if large, adjust code for t)\n",
    "    print('F nr: {} | Feature values: {} | Time values: {} | Nans found: {}'.format(ft_nr,\n",
    "                                                                                    len(i_n),\n",
    "                                                                         len(i_t),\n",
    "                                                                         (np.isnan(t)).sum()))\n",
    "\n",
    "    # Prepare grouping window\n",
    "    t_window = 0.02\n",
    "    df['t_w'] = (df['t']/t_window).round(0)*t_window\n",
    "\n",
    "    # Calculate average numeric value per time window and add to DataFrame\n",
    "    mean_t_w = df.groupby('t_w')[['v']].agg('median').rename(columns={'v':'mu_v'})\n",
    "    df = df.merge(mean_t_w, how='left', left_on='t_w', right_index=True)\n",
    "    \n",
    "    # Calculate average numeric value per time window and cluster and add to DataFrame\n",
    "    mean_t_w_c = df.groupby(['t_w','c'])[['v']].agg('median').rename(columns={'v':'mu_v_c'})\n",
    "    df = df.set_index(['t_w','c']).merge(mean_t_w_c, how='left', left_index=True, right_index=True).reset_index()\n",
    "\n",
    "    # Above is faster than transform:\n",
    "    # df['mu_v'] = df.groupby('t_w')[['v']].transform('mean')\n",
    "    \n",
    "    # Calculate some differences\n",
    "    df['v_diff_abs'] = df['v'] - df['mu_v_c']\n",
    "    df['v_diff_abs_abs'] = df['v_diff_abs'].abs()\n",
    "    df['v_diff_rel'] = (df['v'] / df['mu_v']).abs()\n",
    "    \n",
    "    if showplot:\n",
    "        # Define figure and axes\n",
    "        plt.figure(figsize=(16,10))\n",
    "        gs = gridspec.GridSpec(4, 5)\n",
    "        ax0 = plt.subplot(gs[0,:]) # Raw data\n",
    "        ax1 = plt.subplot(gs[1,:]) # Detrended data\n",
    "        ax5 = plt.subplot(gs[2,:]) # Detrended data\n",
    "        ax2 = plt.subplot(gs[3,0]) # Histogram of raw values\n",
    "        ax3 = plt.subplot(gs[3,1]) # Histogram of detrended values\n",
    "        ax4 = plt.subplot(gs[3,2]) # Histogram of relative values\n",
    "        ax6 = plt.subplot(gs[3,3]) # Cumulative plot\n",
    "        ax7 = plt.subplot(gs[3,4]) # Relative values per bin\n",
    "\n",
    "        means = df.groupby('r').mean()\n",
    "        xlim = [0, 1750]\n",
    "\n",
    "        plt.suptitle('Feature: {} | Station: {} | <v-> = {:.4f} | <v+> = {:.4f}'.format(ft_nr,\n",
    "                                                                                       station,\n",
    "                                                                                       means.loc[0,'v_diff_abs_abs'],\n",
    "                                                                                       means.loc[1,'v_diff_abs_abs']))\n",
    "        colors = ['r','g','b','k','c','w','m','y']\n",
    "\n",
    "        # Raw values\n",
    "        for cl in cluster_info[cluster].unique():\n",
    "            cl_x = df[df['c']==cl].t\n",
    "            cl_y = df[df['c']==cl].v\n",
    "            \n",
    "            if cl_x.shape[0]>0:\n",
    "                ax0.scatter(cl_x, cl_y, marker='.', color=colors[cl % 8], label='{}: {:.2f}%'.format(cl,\n",
    "                                                                                             float(cl_x.shape[0])/df.shape[0]*100))\n",
    "\n",
    "        ax0.scatter(df.t_w, df.mu_v,color='c', marker='x', s=5)\n",
    "        ax0.set_ylabel('Raw value')\n",
    "        ax0.set_xlim(xlim)\n",
    "\n",
    "        # Add legend\n",
    "        ax0.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "               ncol=cluster_info[cluster].nunique() + 1, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "\n",
    "\n",
    "        # Detrended values\n",
    "        ax1.scatter(df.t, df.v_diff_abs, marker='.', color='g')\n",
    "        ax1.scatter(df.t[df.r==1], df.v_diff_abs[df.r==1], color='r', marker='.', s=100)\n",
    "        ax1.set_ylabel('Detrended')\n",
    "        ax1.set_xlim(xlim)\n",
    "\n",
    "        # Error rates\n",
    "        e_rates = df.groupby('t_w')['r'].agg(['sum','count'])\n",
    "        e_rates['r'] = e_rates['sum'] / e_rates['count']\n",
    "        e_rates['r'].plot(marker='.', linestyle='None', markersize='10', ax=ax5)\n",
    "        ax5.set_ylabel('Error rate')\n",
    "        ax5.set_xlim(xlim)\n",
    "\n",
    "        # Histogram of raw values\n",
    "        nbins = 100\n",
    "        rmax = 0.4\n",
    "        freq_1, bins = np.histogram(df.loc[df['r']==1,'v'], bins=nbins, range=[-rmax, rmax], density=True)\n",
    "        freq_0, bins = np.histogram(df.loc[df['r']==0,'v'], bins=nbins, range=[-rmax, rmax], density=True)\n",
    "\n",
    "        ax2.bar(bins[1:], freq_0, color='g', width=2*rmax/nbins, alpha=0.5)\n",
    "        ax2.bar(bins[1:], freq_1, color='r', width=2*rmax/nbins, alpha=0.5)\n",
    "        ax2.set_ylabel('Raw values')\n",
    "\n",
    "        # Histogram of values after detrending\n",
    "        nbins = 100\n",
    "        rmax = 0.4\n",
    "        freq_1, bins = np.histogram(df.loc[df['r']==1,'v_diff_abs'], bins=nbins, range=[-rmax, rmax], density=True)\n",
    "        freq_0, bins = np.histogram(df.loc[df['r']==0,'v_diff_abs'], bins=nbins, range=[-rmax, rmax], density=True)\n",
    "\n",
    "        ax3.bar(bins[1:], freq_0, color='g', width=2*rmax/nbins, alpha=0.5)\n",
    "        ax3.bar(bins[1:], freq_1, color='r', width=2*rmax/nbins, alpha=0.5)\n",
    "        ax3.set_ylabel('Detrended')\n",
    "\n",
    "        # Relative values per bin\n",
    "        ax4.bar(bins[1:], freq_1/freq_0, color='b', width=2*rmax/nbins, alpha=0.5)\n",
    "        ax4.set_ylabel('Difference')\n",
    "\n",
    "        # Cumulative sum of abs values\n",
    "        df['dummy'] = 1\n",
    "        tmp0 = df[df['r']==0].set_index('v_diff_abs_abs').sort_index()['dummy'].cumsum()\n",
    "        tmp1 = df[df['r']==1].set_index('v_diff_abs_abs').sort_index()['dummy'].cumsum()\n",
    "        ax6.plot(tmp0.index, tmp0.values.astype(float) / tmp0.max(), color='g')\n",
    "        ax6.plot(tmp1.index, tmp1.values.astype(float) / tmp1.max(), color='r')\n",
    "        ax6.set_ylabel('Cumsum')\n",
    "\n",
    "        # Histogram of relative values by detrending\n",
    "        nbins = 40\n",
    "        rmax = 40\n",
    "        freq_0, bins = np.histogram(df.loc[df['r']==0,'v_diff_rel'], bins=nbins, range=[0, rmax], density=True)\n",
    "        freq_1, bins = np.histogram(df.loc[df['r']==1,'v_diff_rel'], bins=nbins, range=[0, rmax], density=True)\n",
    "\n",
    "        ax7.bar(bins[1:], freq_0, color='g', width=rmax/nbins, alpha=0.5)\n",
    "        ax7.bar(bins[1:], freq_1, color='r', width=rmax/nbins, alpha=0.5)\n",
    "        ax7.set_ylabel('Relative detrending')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F nr: 3354 | Feature values: 2239066 | Time values: 2239066 | Nans found: 0\n"
     ]
    }
   ],
   "source": [
    "a = visualize_detrended_numeric_feature(3354, cluster='cluster_n25', showplot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F nr: 0 | Feature values: 1348366 | Time values: 1348366 | Nans found: 2\n",
      "F nr: 2 | Feature values: 1348366 | Time values: 1348366 | Nans found: 2\n",
      "F nr: 4 | Feature values: 1348366 | Time values: 1348366 | Nans found: 2\n"
     ]
    }
   ],
   "source": [
    "data_detrended = data.copy()\n",
    "\n",
    "for f_nr in lut['feature_nr'].unique():\n",
    "    a = visualize_detrended_numeric_feature(f_nr, showplot=False, cluster='cluster_n25')\n",
    "    if isinstance(a, pd.DataFrame):\n",
    "        # Update values in sparse array\n",
    "        n_col = lut[lut.feature_nr==f_nr].col_num.values[0]\n",
    "        i_n = data[:, n_col].nonzero()[0]\n",
    "        \n",
    "        # To not mess up sparse structure\n",
    "        a.loc[a['v_diff_abs']==0,'v_diff_abs'] = 1e-5\n",
    "        \n",
    "        data_detrended[a['i'].values, n_col] = a['v_diff_abs'].values.reshape(-1,1)\n",
    "    else:\n",
    "        print('No numeric data for feature {}'.format(f_nr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(const.DATA_PATH, 'feat_set_numeric_detrended.pkl'), 'wb') as f:\n",
    "    pickle.dump(data_detrended, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#pd.concat([ids,pd.DataFrame(data_detrended.todense())], axis=1).to_csv(os.path.join(const.DATA_PATH, 'feat_set_numeric_detrended.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_values_per_cluster(a):\n",
    "    ''' Visualizes the distribution of numeric values per clusters\n",
    "    a is the output of visualize_detrended_numeric_feature()\n",
    "    '''\n",
    "    cl_col = 'c50'\n",
    "    n_col = 50\n",
    "\n",
    "    for cl in range(n_col):\n",
    "        print a[a[cl_col]==cl].shape[0], a[a[cl_col]==cl].v.nunique()\n",
    "        if a[a[cl_col]==cl].shape[0]>100:\n",
    "            f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=True, figsize=(16,6))\n",
    "            #a[a.c500==cl].v.hist(bins=100)\n",
    "\n",
    "            # Histogram of raw values\n",
    "            nbins = 50\n",
    "            rmax = 0.3\n",
    "            freq_2, bins = np.histogram(a.loc[(a[cl_col]==cl),'v'], bins=nbins, range=[-rmax, rmax])\n",
    "            freq_1, bins = np.histogram(a.loc[(a[cl_col]==cl) & (a['r']==1),'v'], bins=nbins, range=[-rmax, rmax], density=True)\n",
    "            freq_0, bins = np.histogram(a.loc[(a[cl_col]==cl) & (a['r']==0),'v'], bins=nbins, range=[-rmax, rmax], density=True)\n",
    "            freq_1r, bins = np.histogram(a.loc[(a[cl_col]==cl) & (a['r']==1),'v'], bins=nbins, range=[-rmax, rmax])\n",
    "            ax1.set_title('<v> = {:.4f}'.format(a.loc[(a[cl_col]==cl),'v'].mean()))\n",
    "            ax2.set_title('<v-> = {:.4f}'.format(a.loc[(a[cl_col]==cl) & (a['r']==0),'v'].mean()))\n",
    "            ax3.set_title('<v+> = {:.4f}'.format(a.loc[(a[cl_col]==cl) & (a['r']==1),'v'].mean()))\n",
    "\n",
    "            ax1.bar(bins[1:], freq_2, color='b', width=2*rmax/nbins, alpha=1)\n",
    "            ax2.bar(bins[1:], freq_0, color='g', width=2*rmax/nbins, alpha=0.5)\n",
    "            ax2.bar(bins[1:], freq_1, color='r', width=2*rmax/nbins, alpha=0.5)\n",
    "            ax3.bar(bins[1:], freq_1r, color='r', width=2*rmax/nbins, alpha=0.5)\n",
    "            plt.show()\n",
    "            \n",
    "def visualize_per_time(a):\n",
    "    ''' Visualizes the distribution of numeric values per timeunit\n",
    "    a is the output of visualize_detrended_numeric_feature()\n",
    "    '''\n",
    "    # square root of number of time splits\n",
    "    n = 5\n",
    "\n",
    "    f, ax = plt.subplots(n,n,sharex=True, figsize=(16,16))\n",
    "\n",
    "    t_split = np.linspace(0, a['t'].max(), n ** 2 +1)\n",
    "\n",
    "    for i in range(n ** 2):\n",
    "\n",
    "        tmin = t_split[i]\n",
    "        tmax = t_split[i+1]\n",
    "        #print tmin, tmax\n",
    "        # Histogram of raw values\n",
    "        nbins = 50\n",
    "        rmax = 0.3\n",
    "        freq_2, bins = np.histogram(a.loc[(a['t']>=tmin) & (a['t']<=tmax),'v'], bins=nbins, range=[-rmax, rmax])\n",
    "        freq_1, bins = np.histogram(a.loc[(a['t']>=tmin) & (a['t']<=tmax) & (a['r']==1),'v'], bins=nbins, range=[-rmax, rmax], density=True)\n",
    "        freq_0, bins = np.histogram(a.loc[(a['t']>=tmin) & (a['t']<=tmax) & (a['r']==0),'v'], bins=nbins, range=[-rmax, rmax], density=True)\n",
    "        freq_1r, bins = np.histogram(a.loc[(a['t']>=tmin) & (a['t']<=tmax) & (a['r']==1),'v'], bins=nbins, range=[-rmax, rmax])\n",
    "        #ax1.set_title('<v> = {:.4f}'.format(a.loc[(a[cl_col]==cl),'v'].mean()))\n",
    "        #ax2.set_title('<v-> = {:.4f}'.format(a.loc[(a[cl_col]==cl) & (a['r']==0),'v'].mean()))\n",
    "        #ax3.set_title('<v+> = {:.4f}'.format(a.loc[(a[cl_col]==cl) & (a['r']==1),'v'].mean()))\n",
    "\n",
    "        ax[i / n, i % n].bar(bins[1:], freq_2, color='b', width=2*rmax/nbins, alpha=1)\n",
    "        #ax[i / 9, 9 % i].bar(bins[1:], freq_0, color='g', width=2*rmax/nbins, alpha=0.5)\n",
    "        #ax[i / 9, 9 % i].bar(bins[1:], freq_1, color='r', width=2*rmax/nbins, alpha=0.5)\n",
    "        #ax[i / 9, 9 % i].bar(bins[1:], freq_1r, color='r', width=2*rmax/nbins, alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_timestamp_coverage_per_feature():\n",
    "    for n in lut.feature_nr.unique():\n",
    "\n",
    "        station = lut[lut.feature_nr==n].station_V2.values[0]\n",
    "\n",
    "        t_col = lut[lut.feature_nr==n].col_dat.values[0]\n",
    "        # TO-DO: GET TIMING FROM FEATURE WITH TIMES\n",
    "\n",
    "        n_col = lut[lut.feature_nr==n].col_num.values[0]\n",
    "\n",
    "        if np.isnan(n_col):\n",
    "            continue\n",
    "\n",
    "        i_n = data[:, n_col].nonzero()[0]\n",
    "\n",
    "        if np.isnan(t_col):\n",
    "            i_t = 0.0\n",
    "        else:\n",
    "            i_t = set(i_n) & set(t[:, t_col].nonzero()[0])\n",
    "            i_t = 1.0 * len(i_t)\n",
    "\n",
    "\n",
    "        i_ts = (~t_station.iloc[i_n, t_station.columns.get_loc('t_' + str(station))].isnull()).sum()\n",
    "\n",
    "        i_n = 1.0 * len(i_n)\n",
    "\n",
    "        print('F: {} | S: {} | n: {} | t: {} | r: {}% t(S): {}'.format(n, \n",
    "                                                                       station, \n",
    "                                                                       i_n, \n",
    "                                                                       i_t, \n",
    "                                                                       i_t/i_n*100,\n",
    "                                                                       i_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_feature(f_nr):\n",
    "    \n",
    "    t_col = lut[lut.feature_nr==f_nr].col_dat.values[0]\n",
    "    n_col = lut[lut.feature_nr==f_nr].col_num.values[0]\n",
    "    \n",
    "    if np.isnan(n_col):\n",
    "        print('No numeric data for {}'.format(f_nr))\n",
    "        return\n",
    "    \n",
    "    if np.isnan(t_col):\n",
    "        print('No timestamp data for {}'.format(f_nr))\n",
    "        return\n",
    "    \n",
    "    #try:\n",
    "    if 1:\n",
    "        # Get rows that have values for t AND numeric data\n",
    "        nrow = list((set(t[:, t_col].nonzero()[0]) & set(data[:, n_col].nonzero()[0])))\n",
    "        nrow_1 = list(set(nrow) & set(n_1))\n",
    "        nrow_0 = list(set(nrow) & set(n_0))\n",
    "\n",
    "        t0 = t[nrow_0[:250000], t_col].todense()\n",
    "        d0 = data[nrow_0[:250000], n_col].todense()\n",
    "        t1 = t[nrow_1, t_col].todense()\n",
    "        d1 = data[nrow_1, n_col].todense()\n",
    "\n",
    "        # Sort arrays\n",
    "        s_t0 = np.argsort(t0, axis=0)\n",
    "        s_t1 = np.argsort(t1, axis=0)\n",
    "\n",
    "        t0 = t0[s_t0].ravel().T\n",
    "        d0 = d0[s_t0].ravel().T\n",
    "        t1 = t1[s_t1].ravel().T\n",
    "        d1 = d1[s_t1].ravel().T\n",
    "\n",
    "        df_0 = pd.DataFrame(np.concatenate([t0,d0], axis=1), columns=['t0','d0'])\n",
    "        df_1 = pd.DataFrame(np.concatenate([t1,d1], axis=1), columns=['t1','d1'])\n",
    "        df_0.loc[:, 't0'] = df_0['t0'].round(0)\n",
    "        df_1.loc[:, 't1'] = df_1['t1'].round(0)\n",
    "\n",
    "        df_0_agg = df_0.groupby('t0').agg(['mean','count'])\n",
    "        df_1_agg = df_1.groupby('t1').agg(['mean','count'])\n",
    "\n",
    "        df_all = df_0_agg.merge(df_1_agg, left_index=True, right_index=True, how='outer').fillna(0)\n",
    "\n",
    "        f, (ax1, ax2, ax3, ax4) = plt.subplots(4,1,figsize=(16,6), sharex=True)\n",
    "        ax1.plot(t0, d0, linestyle='None', marker='.', color='g')\n",
    "        ax1.plot(t1, d1, linestyle='None', marker='.', color='r')\n",
    "        ax1.set_ylabel('Value')\n",
    "        ax1.set_title('Line {} | Station {} | Feature {} '.format(lut[lut.feature_nr==f_nr].line.values[0],\n",
    "                                                                  lut[lut.feature_nr==f_nr].station_V2.values[0],\n",
    "                                                                  f_nr))\n",
    "\n",
    "        ax2.plot(df_0_agg.index, df_0_agg['d0']['mean'], color='g')\n",
    "        ax2.plot(df_1_agg.index, df_1_agg['d1']['mean'], color='r')\n",
    "        ax2.set_ylabel('Moving average')\n",
    "\n",
    "        ax3.plot(df_all.index, df_all['d1']['count'].astype(float).div(df_all['d0']['count']), color='b')\n",
    "        ax3.set_ylabel('Error rate')\n",
    "        ax3.set_xlabel('Timestamp')\n",
    "        ax3.set_ylim([0, 0.1])\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
